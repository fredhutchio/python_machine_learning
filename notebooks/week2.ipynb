{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the import cell below says you don't have scikit-learn (sklearn), best to install using conda and the terminal.\n",
    "# Open a new terminal window. Run the following `conda install scikit-learn` then try running the import cell again.\n",
    "# Visit `https://scikit-learn.org/stable/install.html` for more help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portions of today's lesson were adapted from materials developed by Matt Drury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fredhutch.io -- Intermediate Python: Machine Learning\n",
    "Fred Hutchinson Cancer Research Center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 -- Case Study in Regression\n",
    "We have access to a set of data describing a variety of features about people's commutes. We're hoping to use these data to predict how long a new person's commute will be given some information about them. Can machine learning help us achieve our goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By the end of today's class, you should be able to:\n",
    "* Visualize single variables in different ways and plot continuous features against categorical features to highlight notable patterns (this lesson isn't about plotting specifically, but I'm hoping the plots here will help you create your own)\n",
    "* Engineer new features (columns) for our dataset using existing features and/or specific functions written for that purpose\n",
    "* Set-up, fit, and evaluate different models for our problem, including linear regression and random forests\n",
    "* Understand the basic structure and some of the strengths and draw-backs of the two models we fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throughout we've scattered pairs of cells like the 2 immediately below. Use them to note your thoughts, answers to questions, and the code you're experimenting with.\n",
    "(remember that you can change the type of a cell by going into command mode (cell highlighted in blue) and pressing `m` for markdown and `y` for code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../data/commute-times-train.csv'\n",
    "TEST_DATA_PATH = '../data/commute-times-test.csv'\n",
    "# Why might it be helpful to save these paths strings to variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv(TRAIN_DATA_PATH, \n",
    "                             parse_dates=['time_of_day_ts'])\n",
    "test_data_raw = pd.read_csv(TEST_DATA_PATH,\n",
    "                            parse_dates=['time_of_day_ts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data (One Variable) Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source and Destination of Commute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].scatter(train_data_raw['source_latitude'],\n",
    "               train_data_raw['source_longitude'],\n",
    "               color=\"grey\", alpha=0.02)\n",
    "axs[0].set_title(\"Source Of Commute Lat, Long\")\n",
    "axs[1].scatter(train_data_raw['destination_latitude'],\n",
    "               train_data_raw['destination_longitude'],\n",
    "               color=\"grey\", alpha=0.02)\n",
    "axs[1].set_title(\"Destination Of Commute Lat, Long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of Commute Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "train_data_raw.groupby('commute_type').size().plot(\n",
    "    ax=ax, kind='bar', color=\"grey\")\n",
    "ax.set_title(\"Count of Commute Types\")\n",
    "ax.set_xlabel(\"Transportation Type of Commute\")\n",
    "ax.set_ylabel(\"Volume of Commutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Commute Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "train_data_raw['commute_time'].plot(\n",
    "    ax=ax, kind='hist', bins=50, color=\"grey\")\n",
    "ax.set_title(\"Histogram of Commute Times\")\n",
    "ax.set_xlabel(\"Length of Commute\")\n",
    "ax.set_ylabel(\"Volume of Commutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion.**\n",
    "\n",
    "Discuss multi-modal nature.  What could be causing that?  **A:** We may have different subpopulations in the data with different commute time behavior. Transportation type is a possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Time of Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to draw a histogram of time of day, but this is not easy to do on the raw timestamp data.  To make our lives easy, we'll convert this into a decimal between zero and twenty-four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_decimal(ts):\n",
    "    \"\"\"Convert a timestamp datum into a decimal between zero and twenty-four.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts: pd.Series of datetime.\n",
    "    \"\"\"\n",
    "    return ts.dt.hour + (1/60)*ts.dt.minute\n",
    "\n",
    "train_data_raw['time_of_day'] = timestamp_to_decimal(\n",
    "    train_data_raw['time_of_day_ts'])\n",
    "test_data_raw['time_of_day'] = timestamp_to_decimal(\n",
    "    test_data_raw['time_of_day_ts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we have to apply the **same transformation** to our training and testing data.  I'll show you a trick soon that will save us some trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "train_data_raw['time_of_day'].plot(\n",
    "    ax=ax, kind='hist', bins=50, color='grey')\n",
    "ax.set_title(\"Volume of Commutes by Time of Day\")\n",
    "ax.set_xlabel(\"Time of Day\")\n",
    "ax.set_ylabel(\"Volume of Commutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "We would expect high volume times to have longer commutes.  Plotting the commute time by the time of day may give some insight into the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance of Commute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance of the commute is not explicitly included in the dataset!  Instead, we have the coordinates of the source and destination of the commute.  This should allow us to calculate the distance of the commute, but we have a couple of options:\n",
    "\n",
    "  - The **Euclidean Distance** is the straight line distance between the source and the target.  It is calculated from the usual formula inspired by the Pythagorean Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(source_x, source_y, target_x, target_y):\n",
    "    return np.sqrt((source_x - target_x)**2 + (source_y - target_y)**2)\n",
    "\n",
    "train_data_raw['euclidean_distance'] = euclidean_distance(\n",
    "    train_data_raw['source_latitude'], train_data_raw['source_longitude'],\n",
    "    train_data_raw['destination_latitude'], train_data_raw['destination_longitude'])\n",
    "test_data_raw['euclidean_distance'] = euclidean_distance(\n",
    "    test_data_raw['source_latitude'], test_data_raw['source_longitude'],\n",
    "    test_data_raw['destination_latitude'], test_data_raw['destination_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "train_data_raw['euclidean_distance'].plot(\n",
    "    ax=ax, kind='hist', bins=50, color='grey')\n",
    "ax.set_title(\"Euclidean Commute Distance\")\n",
    "ax.set_xlabel(\"Euclidean Distance\")\n",
    "ax.set_ylabel(\"Volume of Commutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - The **Taxicab Distance** is the total distance a car would travel between the source and destination coordinates *if it only traveled parallel to the x and y axes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxicab_distance(source_x, source_y, target_x, target_y):\n",
    "    return np.abs(source_x - target_x) + np.abs(source_y - target_y)\n",
    "\n",
    "train_data_raw['taxicab_distance'] = taxicab_distance(\n",
    "    train_data_raw['source_latitude'], train_data_raw['source_longitude'],\n",
    "    train_data_raw['destination_latitude'], train_data_raw['destination_longitude'])\n",
    "test_data_raw['taxicab_distance'] = taxicab_distance(\n",
    "    test_data_raw['source_latitude'], test_data_raw['source_longitude'],\n",
    "    test_data_raw['destination_latitude'], test_data_raw['destination_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "train_data_raw['taxicab_distance'].plot(\n",
    "    ax=ax, kind='hist', bins=50, color='grey')\n",
    "ax.set_title(\"Taxicab Commute Distance\")\n",
    "ax.set_xlabel(\"Taxicab Distance\")\n",
    "ax.set_ylabel(\"Volume of Commutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "Which distance measure do you think more likely to be related to the commute time?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "The code above was a lot to read and pretty repetitious.\n",
    "We've mentioned the idea of avoiding repeated code where possible.\n",
    "What could we do to avoid having to type the same code multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this template to start if you want. \n",
    "# The docstring format below is one common convention.\n",
    "# There are other good conventions represented elsewhere in FH materials.\n",
    "# None of these is exactly right or wrong, but the important things are consistency and clarity.\n",
    "def create_distance_features(df):\n",
    "    \"\"\"Describe what the function does here.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: Important notes about our argument df here.\n",
    "    \"\"\"\n",
    "    pass\n",
    "# I've included a possible solution at the bottom of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Effect Of Commute Type on Commute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to look into the relationship between the commute type and commute time.  We have hypothesized that the commute type may have something to do with the multi-modal behaviour of commute time.\n",
    "\n",
    "A powerful technique in this area is the principle of **small multiples**, draw many small separate plots in a way that the readers eye can easily compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the unique commute types.\n",
    "commute_types = np.unique(train_data_raw['commute_type'])\n",
    "\n",
    "# We want one axis (i.e. on plotting area) for each commute type.\n",
    "# Note the sharex argument, this forces all out plots to have the \n",
    "# same x-axis range.\n",
    "fig, axs = plt.subplots(len(commute_types), 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Subset the data by each commute type, then plot a histogram of commute\n",
    "# times for each separate commute type individually.\n",
    "for commute_type, ax in zip(commute_types, axs):\n",
    "    commute_type_mask = train_data_raw['commute_type'] == commute_type\n",
    "    train_for_commute_type = train_data_raw[commute_type_mask]\n",
    "    train_for_commute_type['commute_time'].plot(ax=ax, kind=\"hist\", bins=50)\n",
    "    ax.set_title(\"Commute Time Histogram for {0} Commuters\".format(\n",
    "        commute_type))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the commute type definitely has an effect.\n",
    "\n",
    "The results here are intuitive:  train commutes are speedy, while walking or biking to work takes longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an alternative visualization of this effect (though making this one is a bit more involved)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric(categorical):\n",
    "    classes = list(sorted(categorical.unique()))\n",
    "    classes_mapping = {cls: i for i, cls in enumerate(classes)}\n",
    "    classes_inv_mapping = {i: cls for i, cls in enumerate(classes)}\n",
    "    classes_numeric = categorical.apply(lambda cls: classes_mapping[cls])\n",
    "    return classes_numeric, classes_inv_mapping\n",
    "\n",
    "def categorical_plot(ax, categorical, y, jitter_width=0.1, box=True):\n",
    "    numeric, classes_mapping = convert_to_numeric(categorical)\n",
    "    # This is called adding \"jitter\" to a scatterplot.\n",
    "    noise = np.random.normal(0.0, jitter_width, size=len(categorical))\n",
    "    ax.scatter(numeric + noise, y, color=\"grey\", alpha=0.1, label=\"Data\")\n",
    "    \n",
    "    box_data = list(y.groupby(numeric))\n",
    "    if box:\n",
    "        ax.boxplot([data for _, data in box_data], positions=range(len(box_data)))\n",
    "    ax.set_xticks(list(classes_mapping))\n",
    "    ax.set_xticklabels([classes_mapping[name] for name, _ in box_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "categorical_plot(ax, train_data_raw['commute_type'], train_data_raw['commute_time'])\n",
    "ax.set_xlabel(\"Commute Type\")\n",
    "ax.set_ylabel(\"Commute Time\")\n",
    "ax.set_title(\"Effect of Commute Type on Commute Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells the same story in a different way.  Here we see each individual commute time as a point, so all the data is represented exactly.  Each cloud of points are the commute times for each individual type of commute.\n",
    "\n",
    "The left-right scatter within each type of commute is not meaningful, it just serves to spread the points out so our eye can get an idea of what is going on.  If we take away the scatter, it looks really bad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "categorical_plot(ax, \n",
    "                 train_data_raw['commute_type'], \n",
    "                 train_data_raw['commute_time'],\n",
    "                 jitter_width=0.0)\n",
    "ax.set_xlabel(\"Commute Type\")\n",
    "ax.set_ylabel(\"Commute Time\")\n",
    "ax.set_title(\"Effect of Commute Type on Commute Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "Do you expect commute type to be predictive of commute time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Effect of Commute Distance on Commute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatter plot of commute time by commute distance can be illuminating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_data_raw.plot(ax=ax, kind='scatter', x='euclidean_distance', y='commute_time',\n",
    "                    color='gray', alpha=0.5)\n",
    "ax.set_title(\"Commute Time by Euclidean Commute Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_data_raw.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                    color='gray', alpha=0.5)\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly a relationship between commute distance and commute time!  Though it is subtle:\n",
    "\n",
    "  - There is *definitely* some overall relationship between the distance of the commute and the time of the commute.  Commutes covering a larger distance tend to take longer, which makes intuitive sense.\n",
    "  - There is some interesting *banding* in these plots.  The relationships seem to fall into different categories.\n",
    "  - The structure of the Taxicab distance plot is more defined than the structure of the Euclidean distance plot.  This maybe leads us to suspect that the taxicab distance is closer to capturing some essential truth of the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the banding.  We suspect that each defined band is some subpopulation of our commuters.  We have a clear candidate for what this could be, our commute type variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is based on the example from earlier which creates histograms of \n",
    "# commute time for each individual commute type.\n",
    "commute_types = np.unique(train_data_raw['commute_type'])\n",
    "\n",
    "fig, axs = plt.subplots(len(commute_types), 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "for commute_type, ax in zip(commute_types, axs):\n",
    "    commute_type_mask = train_data_raw['commute_type'] == commute_type\n",
    "    train_for_commute_type = train_data_raw[commute_type_mask]\n",
    "    train_data_raw.plot(\n",
    "        ax=ax, kind=\"scatter\", \n",
    "        x='taxicab_distance', y='commute_time',\n",
    "        color='gray', alpha=0.02)\n",
    "    train_for_commute_type.plot(\n",
    "        ax=ax, kind=\"scatter\", \n",
    "        x='taxicab_distance', y='commute_time',\n",
    "        color='blue', alpha=0.2)\n",
    "    ax.set_title(\"Commute Distance vs. Commute Time for {0} Commuters\".format(\n",
    "        commute_type))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see clearly that the banding structure in the scatterplot is caused by the different types of commute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Effect of Time of Day on Commute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look into the relationship between the commute time and the time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_data_raw.plot(ax=ax, kind='scatter', x='time_of_day', y='commute_time',\n",
    "                    color='gray', alpha=0.5)\n",
    "ax.set_title(\"Commute Time by Time of Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again see some banding structure, so lets break it out by commute type to get a clearer picture of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_types = np.unique(train_data_raw['commute_type'])\n",
    "\n",
    "fig, axs = plt.subplots(len(commute_types), 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "for commute_type, ax in zip(commute_types, axs):\n",
    "    commute_type_mask = train_data_raw['commute_type'] == commute_type\n",
    "    train_for_commute_type = train_data_raw[commute_type_mask]\n",
    "    train_data_raw.plot(\n",
    "        ax=ax, kind=\"scatter\", \n",
    "        x='time_of_day', y='commute_time',\n",
    "        color='gray', alpha=0.02)\n",
    "    train_for_commute_type.plot(\n",
    "        ax=ax, kind=\"scatter\", \n",
    "        x='time_of_day', y='commute_time',\n",
    "        color='blue', alpha=0.2)\n",
    "    ax.set_title(\"Commute Distance vs. Commute Time for {0} Commuters\".format(\n",
    "        commute_type))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, the bands are caused by the different commute types.\n",
    "\n",
    "The relationship between time of day and commute time is subtle.  It's definitely not an increasing style of relationship.  Instead, it looks like commute times are largely driven by the distance, but they tend to be longer during high traffic times of day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: The Classic Workhorse of Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal now is to use the information we've learned from data exploration to build a predictive model that uses the features in the data to make a predicton of commute time.\n",
    "\n",
    "The most important foundational technique for doing this is called **linear regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Commute Type to Predict Commute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the commute type features.  We are almost certain from our data exploration that this feature has a strong influence on the commute time, so let's see if we're right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its a general fact about predictive models that they cannot handle raw categorical data, like our commute time column.  Instead, whenever you would like to use a categorical measurement to make predictions, it is necessary to turn it into some number of **indicator variables**, usually one for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indicator_features(feature, leave_one_out=True):\n",
    "    # Sort the levels so we always get the same ordering of new features.\n",
    "    levels = list(sorted(np.unique(feature)))\n",
    "    # If we need to leave one out to avoid identifiability issues, we will \n",
    "    # leave out the *last* level, in sorted order.\n",
    "    if leave_one_out:\n",
    "        levels = levels[:-1]\n",
    "    indicator_features = []\n",
    "    for level in levels:\n",
    "        indicator_feature = (feature == level)\n",
    "        indicator_feature_name = \"is_{0}\".format(level)\n",
    "        indicator_features.append(\n",
    "            pd.Series(indicator_feature, \n",
    "                      name=indicator_feature_name, \n",
    "                      index=feature.index,\n",
    "                      dtype=int))\n",
    "    return pd.concat(indicator_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_type_features_train = create_indicator_features(train_data_raw['commute_type'])\n",
    "commute_type_features_test = create_indicator_features(test_data_raw['commute_type'])\n",
    "\n",
    "commute_type_features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pd.concat([train_data_raw, commute_type_features_train], axis=1)\n",
    "test_data_raw = pd.concat([test_data_raw, commute_type_features_test], axis=1)\n",
    "\n",
    "train_data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're prepared now.\n",
    "\n",
    "We're going to fit a linear regression model which uses the commute type information to predict the commute distance.  The result of this will be an equation:\n",
    "\n",
    "$$ \\text{Commute Time} \\approx \\beta_0 + \\beta_1 \\times \\text{is_BIKE} + \\beta_2 \\times \\text{is_BUS} + \\beta_3 \\times \\text{is_CAR} + \\beta_4 \\times \\text{is_TRAIN} $$\n",
    "\n",
    "The $\\beta$ things are just numbers.  The whole idea is to use the **data** to choose the numbers $\\beta_0, \\beta_1, \\ldots, \\beta_4$ so that the equation above is the **most descriptive of the data possible**.\n",
    "\n",
    "When we call the `LinearRegression.fit` function below, this is what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['is_BIKE', 'is_BUS', 'is_CAR', 'is_TRAIN']\n",
    "\n",
    "train_data_only_commute_type = train_data_raw.loc[:, feature_names]\n",
    "test_data_only_commute_type = test_data_raw.loc[:, feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_only_commute_type = LinearRegression()\n",
    "model_only_commute_type.fit(train_data_only_commute_type, train_data_raw['commute_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've fit the model to our data, the beta numbers are available from the model object:\n",
    "\n",
    "  - The `model.intercept_` attribute contains $\\beta_0$.\n",
    "  - The `model.coef_` attribute contains $\\beta_1, \\beta_2, \\ldots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_only_commute_type.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_only_commute_type.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the model object does **not** remember the names of the features, so let's write a function to stitch together the names of the features with the values of the betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_betas(model, feature_names):\n",
    "    feature_names = [\"Intercept\"] + feature_names\n",
    "    betas = [model.intercept_] + list(model.coef_)\n",
    "    for name, beta in zip(feature_names, betas):\n",
    "        print(\"{0:<20}: {1:2.2f}\".format(name, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_betas(model_only_commute_type, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's interpret this in light of our equation:\n",
    "\n",
    "$$ \\begin{align} \\text{Commute Time} \\ \\approx \\ & \\beta_0 + \\beta_1 \\times \\text{is_BIKE} \\\\&+ \\beta_2 \\times \\text{is_BUS} \\\\&+ \\beta_3 \\times \\text{is_CAR} \\\\&+ \\beta_4 \\times \\text{is_TRAIN}\\\\ \\end{align} $$\n",
    "\n",
    "Which we can now plug numbers into:\n",
    "\n",
    "$$ \\begin{align} \\text{Commute Time} \\ \\approx \\ & 39.05 - 12.22 \\times \\text{is_BIKE} \\\\&- 15.70 \\times \\text{is_BUS} \\\\&- 25.29 \\times \\text{is_CAR} \\\\&- 28.50 \\times \\text{is_TRAIN}\\\\ \\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can play with this a bit to get some intuition.  For example, the predicted commute time for bike commuters is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Commute Time} \\approx 39.05 - 12.22 \\times 1 - 15.70 \\times 0 - 25.29 \\times 0 - 28.50 \\times 0 = 26.83 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the predicted commute time for train commuters is:\n",
    "\n",
    "$$ \\text{Commute Time} \\approx 39.05 - 12.22 \\times 0 - 15.70 \\times 0 - 25.29 \\times 0 - 28.50 \\times 1 = 10.55 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "How can we get the predicted commute time for walk commuters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working though this by hand (there are better ways to do this, I'll show you soon), we get the following predicted values for each commute type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_commute_type = {\n",
    "    'BIKE': 26.83,\n",
    "    'BUS': 23.25,\n",
    "    'CAR': 13.75,\n",
    "    'TRAIN': 10.55,\n",
    "    'WALK': 39.05\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's superimpose this on our scatter plot of this relationship from earlier to hopefully see what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "categorical_plot(ax, train_data_raw['commute_type'], train_data_raw['commute_time'], box=False)\n",
    "ax.scatter(range(5), predictions_by_commute_type.values(),\n",
    "           color=\"black\", s=100, label=\"Predicted Value\")\n",
    "ax.set_xlabel(\"Commute Type\")\n",
    "ax.set_ylabel(\"Commute Time\")\n",
    "ax.set_title(\"Effect of Commute Type on Commute Time\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks reasonable.  Although the actual commute times vary a lot within each group, the predictions from the model find the center of each group.  This is about the best we could ask for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Commute Distance to Predict Commute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets turn to a different type of variable, the commute distance.\n",
    "\n",
    "Here's our plot of the relationship from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_data_raw.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                    color='gray', alpha=0.5, label=\"Data\")\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that the commute time tends to increase with the distance covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas our previous example used a categorical feature in the model, this time we have a **continuous** feature.  There are many ways to handle continuous features in a linear regression model, but we will focus on the most basic way today, fitting a line through the feature.  This will give us an equation like:\n",
    "\n",
    "$$ \\text{Commute Time} \\approx \\beta_0 + \\beta_1 \\times \\text{Commute Distance} $$\n",
    "\n",
    "This is actually easier than before, we don't need to fuss with the feature at all, since it is already numeric (as opposed to the commute type feature, which was not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['taxicab_distance']\n",
    "\n",
    "train_data_only_distance = train_data_raw.loc[:, feature_names]\n",
    "test_data_only_distance = test_data_raw.loc[:, feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_only_distance = LinearRegression()\n",
    "model_only_distance.fit(train_data_only_distance, train_data_raw['commute_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_betas(model_only_distance, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got the following equation which best describes our data:\n",
    "\n",
    "$$ \\text{Commute Time} \\approx 18.43 + 1.14 \\times \\text{Commute Distance} $$\n",
    "\n",
    "It's good that the coefficient of commute distance came out to a **positive** number.  At the very least our model confirms that longer distances are paired with longer commute times.  If it had come out the other way around, we would have reason to doubt our work!\n",
    "\n",
    "The equation we received from the model describes a line (it looks like `m x + b`, in classic algebra style).  This observation allows us to plot the relationship between commute time, and our prediction of commute time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(ax, slope, intercept, linewidth=3, color=\"black\", label=\"\"):\n",
    "    t = np.linspace(0.0, 3.0, num=250)\n",
    "    ax.plot(t, intercept + slope * t, label=label, \n",
    "            linewidth=linewidth, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_data_raw.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                    color='gray', alpha=0.5, label=\"Data\")\n",
    "plot_line(ax, model_only_distance.coef_, model_only_distance.intercept_, label=\"Predictions\")\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance\")\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, not so pretty.\n",
    "\n",
    "**Discussion**\n",
    "\n",
    "Why does this line look so flat?  Is there any way we can remedy it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Both to Predict Commute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct the bad fit of the last time, we can use **both** sets of features in a linear regression.  This results in an equation like:\n",
    "\n",
    "$$ \\begin{align} \\text{Commute Time} \\ \\approx \\ & \\beta_0 + \\beta_1 \\times \\text{Commute Time} \\\\&+ \\beta_2 \\times \\text{is_BIKE} \\\\&+ \\beta_3 \\times \\text{is_BUS} \\\\&+ \\beta_4 \\times \\text{is_CAR} \\\\&+ \\beta_5 \\times \\text{is_TRAIN}\\\\ \\end{align} $$\n",
    "\n",
    "Note that we are mixing two different types of variables here.\n",
    "\n",
    "  - The commute time variable is continuous, and its coefficient $\\beta_1$ represents a slope.\n",
    "  - The indicator variables are on or off, and their coefficients $\\beta_2, \\beta_3, \\ldots$ represent simple additive adjustments.\n",
    "  \n",
    "I'll show you more clearly what I mean after we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['is_BIKE', 'is_BUS', 'is_CAR', 'is_TRAIN', 'taxicab_distance']\n",
    "\n",
    "train_data_both_distance_and_type = train_data_raw.loc[:, feature_names]\n",
    "test_data_both_distance_and_type = test_data_raw.loc[:, feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_both_distance_and_type = LinearRegression()\n",
    "model_both_distance_and_type.fit(train_data_both_distance_and_type, train_data_raw['commute_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_betas(model_both_distance_and_type, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the equation our regression has found as most representative of the training data is:\n",
    "\n",
    "$$ \\begin{align} \\text{Commute Time} \\ \\approx \\ & 35.69 + 5.50 \\times \\text{Commute Distance} \\\\&  - 14.20 \\times \\text{is_BIKE} \\\\&- 18.71 \\times \\text{is_BUS} \\\\&- 28.59 \\times \\text{is_CAR} \\\\&- 32.96 \\times \\text{is_TRAIN}\\\\ \\end{align} $$\n",
    "\n",
    "Let's take a minute to think about what this means.\n",
    "\n",
    "Take the case of **bus commuters**.  For these commuters, the feature `is_BUS` is equal to one, and all other commute type features are zero.  So, plugging these values into the above equation we get:\n",
    "\n",
    "$$ \\begin{align} \\text{Commute Time for Bus Commuters} &= 35.69 + 5.50 \\times \\text{Commute Distance} - 18.71 \\\\ &= 16.98 + 5.50 \\times \\text{Commute Distance} \\end{align} $$\n",
    "\n",
    "So the model has given us a linear relationship that describes how the commute time varies with respect to commute distance for bus commuters.\n",
    "\n",
    "Let's do one more, for walk commuters, all the commute type features are zero, and our equation reduces to:\n",
    "\n",
    "$$\\text{Commute Time for Walk Commuters} = 35.69 + 5.50 \\times \\text{Commute Distance} $$\n",
    "\n",
    "We also get a linear relationship for walk commuters, though a different one than for bus commuters.\n",
    "\n",
    "Let's plot and label all of these lines on the same axis, so we can easily compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_intercepts = {\n",
    "    'BIKE': 35.69 - 14.20,\n",
    "    'BUS': 35.69 - 18.71,\n",
    "    'CAR': 35.69 - 28.59,\n",
    "    'TRAIN': 35.69 - 32.96,\n",
    "    'WALK': 35.69\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_types = np.unique(train_data_raw['commute_type'])\n",
    "colors = [\"black\", \"blue\", \"red\", \"purple\", \"orange\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4), sharex=True)\n",
    "\n",
    "train_data_raw.plot(\n",
    "    ax=ax, kind=\"scatter\", \n",
    "    x='taxicab_distance', y='commute_time',\n",
    "    color='gray', alpha=0.2)\n",
    "for commute_type, color in zip(commute_types, colors):\n",
    "    commute_type_mask = train_data_raw['commute_type'] == commute_type\n",
    "    train_for_commute_type = train_data_raw[commute_type_mask]\n",
    "    plot_line(ax, 5.50, line_intercepts[commute_type], \n",
    "              label=commute_type, color=color)\n",
    "    ax.set_title(\"Commute Distance vs. Commute Time\")\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that what we've managed to fit a sequence of **parallel lines**.  Each one describes the relationship between the commute distance and the commute time, but for a different type of commuter.\n",
    "\n",
    "This is a pretty large increase in the fidelity of our model, and the fit is starting to look pretty good.  This is even more evident if we break each line out into its own plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_types = np.unique(train_data_raw['commute_type'])\n",
    "\n",
    "fig, axs = plt.subplots(len(commute_types), 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "for commute_type, ax in zip(commute_types, axs):\n",
    "    commute_type_mask = train_data_raw['commute_type'] == commute_type\n",
    "    train_for_commute_type = train_data_raw[commute_type_mask]\n",
    "    train_data_raw.plot(\n",
    "        ax=ax, kind=\"scatter\", \n",
    "        x='taxicab_distance', y='commute_time',\n",
    "        color='gray', alpha=0.02)\n",
    "    train_for_commute_type.plot(\n",
    "        ax=ax, kind=\"scatter\", \n",
    "        x='taxicab_distance', y='commute_time',\n",
    "        color='blue', alpha=0.05)\n",
    "    plot_line(ax, 5.50, line_intercepts[commute_type])\n",
    "    ax.set_title(\"Commute Distance vs. Commute Time for {0} Commuters\".format(\n",
    "        commute_type))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So How Are These Lines Determined?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been satisfied with using python to fit or linear regressions, and have not thought much about how the coefficients are actually being determined, now lets loop back around and work this out.\n",
    "\n",
    "**Let's simplify out life a bit so that the story is a bit easier to follow.**  Instead of working with the entire data set, lets subset to just bus commuters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_commuter_mask = train_data_raw['commute_type'] == 'BUS'\n",
    "bus_commuters_train = train_data_raw.loc[bus_commuter_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "bus_commuters_train.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                         color='gray', alpha=0.5)\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance For Bus Commuters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's only use a hundred or so data points so we can draw out what is going on without being overwhelmed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_commuters_train = bus_commuters_train.iloc[:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "bus_commuters_train.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                         color='black', alpha=1.0)\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance For Bus Commuters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same methodology as before, let's fit a line to this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['taxicab_distance']\n",
    "bus_commuters_only_distance = bus_commuters_train.loc[:, feature_names]\n",
    "\n",
    "bus_only_model = LinearRegression()\n",
    "bus_only_model.fit(bus_commuters_only_distance, bus_commuters_train['commute_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "bus_commuters_train.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                         color='black', alpha=1.0)\n",
    "plot_line(ax, bus_only_model.coef_, bus_only_model.intercept_, color=\"grey\")\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance For Bus Commuters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question we want to answer is: **how was this line determined**.  So far we have just said:\n",
    "\n",
    "> The line that best describes the data.\n",
    "\n",
    "But what does \"best\" mean, how do we measure the \"goodness\" or \"badness\" of a line?\n",
    "\n",
    "The answer involves the concept of **residuals**, which is everywhere in machine learning.  The residuals are the vertical distances from the predicted values (along the line in this case) to the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "bus_commuters_train.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                         color='black', alpha=1.0)\n",
    "plot_line(ax, bus_only_model.coef_, bus_only_model.intercept_, color=\"grey\")\n",
    "\n",
    "for (_, row), y in zip(bus_commuters_train.iterrows(),\n",
    "                       bus_commuters_train['commute_time']):\n",
    "    t = row['taxicab_distance']\n",
    "    pred = bus_only_model.intercept_ + bus_only_model.coef_ * t\n",
    "    ax.plot((t, t), (y, pred), color='orange')\n",
    "\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance For Bus Commuters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the residuals are a reasonable measure of the \"goodness\" of the prediction at some data point.\n",
    "\n",
    "For reason that we must leave unexplored, instead it is the **square** of the length of the residuals that we use as our measure of \"goodness\".  Overall, we use the **mean length of the squared residuals** as an overall measure of quality for a given line.\n",
    "\n",
    "Given all that, the principle we use to fit the line to data is:\n",
    "\n",
    "> Among all possible lines, we prefer the one that minimizes the mean of the squared residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measurement of \"badness\" is called the **Mean Squared Error**.  As a formula, it looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Mean Squared Error} = \\frac{1}{\\text{# of Datapoints}} \\sum_i (y_i - \\hat y_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $y_i$ and $\\hat y_i$ notations are very traditional:\n",
    "\n",
    "  - A $y_i$ is the actual measured target value for a single data point.\n",
    "  - A $\\hat y_i$ is the predicted value for a single data point.\n",
    "  \n",
    "So the sub-expression $y_i - \\hat y_i$ is the difference between the actual and predicted values for a single data point.\n",
    "\n",
    "**Discussion:**\n",
    "\n",
    "What's the point of squaring the difference between actual and predicted here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Some people prefer the **Root Mean Squared Error** which is simply the square root of the mean squared error, since shares the same units of measurement as $y$.  Whichever you choose is mostly a matter of taste.\n",
    "\n",
    "$$ \\text{Root Mean Squared Error} = \\sqrt{ \\frac{1}{\\text{# of Datapoints}} \\sum_i (y_i - \\hat y_i)^2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring The Predictive Power of The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we've discussed the mean squared error as a measure of the quality of our predictions, we can write a quick function to calculate it for each of the three models we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(actual, predicted):\n",
    "    assert len(actual) == len(predicted)\n",
    "    n = len(actual)\n",
    "    return (1/n) * np.sum((actual - predicted)**2)\n",
    "\n",
    "def root_mean_squared_error(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the predicted values for all three of our models for all of our training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_commute_type_preds = model_only_commute_type.predict(\n",
    "    train_data_only_commute_type)\n",
    "only_distance_preds = model_only_distance.predict(\n",
    "    train_data_only_distance)\n",
    "both_distance_and_type_preds = model_both_distance_and_type.predict(\n",
    "    train_data_both_distance_and_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use our functions to compute the root mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_distance_rmse = root_mean_squared_error(\n",
    "    only_distance_preds, train_data_raw['commute_time'])\n",
    "only_commute_type_rmse = root_mean_squared_error(\n",
    "    only_commute_type_preds, train_data_raw['commute_time'])\n",
    "both_distance_and_type_rmse = root_mean_squared_error(\n",
    "    both_distance_and_type_preds, train_data_raw['commute_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Only Distance Model RMSE: {0:2.2f}\".format(only_distance_rmse))\n",
    "print(\"Only Commute Type Moddel RMSE: {0:2.2f}\".format(only_commute_type_rmse))\n",
    "print(\"Both Distance and Type RMSE: {0:2.2f}\".format(both_distance_and_type_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our worst model was the only only using distance, and the best was the one that used both distance and commute type, which was more or less what we suspected from our visuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a subtle flaw in our model evaluation scheme.\n",
    "\n",
    "Notice that the more complex models, i.e. the ones that had access to more features, always did better than those that had access to less.  This is **always** true, for the following reason.\n",
    "\n",
    "Each model is determining the $\\beta$s to use, but choosing the ones that **minimize** the mean squared error.  We are then using that **same** measurement to choose the most predictive model.  This is dangerous, any model with strictly more information than another will be able to use this information to lower the mean squared error measurement it is using to determine the best values of $\\beta$, even if that extra information is just random garbage.\n",
    "\n",
    "For this reason, we distinguish between two fundamental types of data:\n",
    "\n",
    "  - **Training** data is the data used by the model to calculate the best values of $\\beta$.  This data becomes polluted by the training process, and cannot be used to honestly compare different models that used it.\n",
    "  - **Testing** data is any data **not** used by any of the models to calculate the best values of $\\beta$.  This data is un-polluted, and has a fair view on the relative merits of the various models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that whenever we created any features to use in our regression models, we did the same thing to both the training and test data (we loaded both sets at the start of the notebook).\n",
    "\n",
    "When we used the `.fit` method to calculate the best $\\beta$s, we **always** used only the training data!  So we can now use the test data to get a fair look at the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_commute_type_preds = model_only_commute_type.predict(\n",
    "    test_data_only_commute_type)\n",
    "only_distance_preds = model_only_distance.predict(\n",
    "    test_data_only_distance)\n",
    "both_distance_and_type_preds = model_both_distance_and_type.predict(\n",
    "    test_data_both_distance_and_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_distance_rmse = root_mean_squared_error(\n",
    "    only_distance_preds, test_data_raw['commute_time'])\n",
    "only_commute_type_rmse = root_mean_squared_error(\n",
    "    only_commute_type_preds, test_data_raw['commute_time'])\n",
    "both_distance_and_type_rmse = root_mean_squared_error(\n",
    "    both_distance_and_type_preds, test_data_raw['commute_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Only Distance Model Test RMSE: {0:2.2f}\".format(only_distance_rmse))\n",
    "print(\"Only Commute Type Moddel Test RMSE: {0:2.2f}\".format(only_commute_type_rmse))\n",
    "print(\"Both Distance and Type Test RMSE: {0:2.2f}\".format(both_distance_and_type_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple case, the results are the same as using the training data.  This is because we have a lot of data, and are not fitting super sophisticated models.  In practice, using training data to evaluate models is **death** (a different **death** than the one arising from training models using test data, but similar in magnitude and finality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus, let's see how the linear regression methodology stands up to a more recent method of building predictive models: the Random Forests of Leo Breiman.\n",
    "\n",
    "The philosophy of a random forest is very different to a linear regression:\n",
    "\n",
    "  - **Linear Regression:** Study the data very hard, and make informed decision about what features to put in the model and how.  Fit one model that incorporates all this information.\n",
    "  - **Random Forests:** Fit many models without worrying much about the way the data works, but take some steps to diversify the models.  Then combine the models by averaging their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=2000, max_features=4, min_samples_split=20)\n",
    "random_forest.fit(train_data_both_distance_and_type, train_data_raw['commute_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_preds = random_forest.predict(test_data_both_distance_and_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_rmse = root_mean_squared_error(\n",
    "    random_forest_preds, test_data_raw['commute_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest RMSE: {0:2.2f}\".format(random_forest_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest pretty easily improves on the predictions of the linear regression.  Let's look at the basic reason why this model did better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Non-Linear Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall out line of best fit to the bus commuters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_data_raw.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                    color='gray', alpha=0.2)\n",
    "\n",
    "plot_line(ax, bus_only_model.coef_, bus_only_model.intercept_, color=\"black\")\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance For Bus Commuters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty clear that a line is not the best choice of curve here.  The general trend of the data steepens for small commute distances and levels off for large distances.\n",
    "\n",
    "One of the reasons random forests tends to be more powerful than linear regression is that it is able to fit more flexible shapes to data.\n",
    "\n",
    "Let's plot out the curve that the random forest fit to our bus commuters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_record = train_data_both_distance_and_type.iloc[:1, :]\n",
    "def create_bus_records(distances):\n",
    "    records = []\n",
    "    for d in distances:\n",
    "        record = one_record.copy()\n",
    "        record['taxicab_distance'] = d\n",
    "        records.append(record)\n",
    "    return pd.concat(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 3.0, num=250)\n",
    "\n",
    "ls = create_bus_records(ts)\n",
    "preds = random_forest.predict(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_data_raw.plot(ax=ax, kind='scatter', x='taxicab_distance', y='commute_time',\n",
    "                    color='gray', alpha=0.2)\n",
    "ax.plot(ts, preds, color=\"black\", linewidth=3, label= \"Random Forest Predictions\")\n",
    "ax.set_title(\"Commute Time by Taxicab Commute Distance\")\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Notes (markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch area (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes, extras, solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible solution to one of the questions above. Did yours look something like this?\n",
    "def create_distance_features(df):\n",
    "    \"\"\"Add 'euclidean_distance' and 'manhattan_distance' feaures to a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.Dataframe with features 'source_latitude', 'source_longitude', 'destination_latitude', \n",
    "    and 'destination_longitude'.\n",
    "    \"\"\"\n",
    "    coordinates = [df['source_latitude'], df['source_longitude'], \n",
    "                   df['destination_latitude'], df['destination_longitude']]\n",
    "    df['euclidean_distance'] = euclidean_distance(coordinates)\n",
    "    df['manhattan_distance'] = manhattan_distance(coordinates)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
